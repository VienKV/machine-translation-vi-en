{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"cnLHJ9PkahlQ"},"source":["#VI-EN Machine Translation using BERT-to-GPT2 Model\n","**Dataset: IWSLT15-en-vi**\n","\n","**khuongvd00@gmail.com**"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":597,"status":"ok","timestamp":1677694886924,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"},"user_tz":-420},"id":"F9fL_h5T8PhQ","outputId":"a3d5925c-8458-4ead-8751-1bffd64da77c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Wed Mar  1 18:21:26 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0    50W / 400W |      0MiB / 40960MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15072,"status":"ok","timestamp":1677694907897,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"},"user_tz":-420},"id":"YcDsZmHz9tHh","outputId":"7561e6e5-bcca-4ea8-9e72-7d7ada5dcc1f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":529,"status":"ok","timestamp":1677694908422,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"},"user_tz":-420},"id":"JO8lLBysFx4w","outputId":"b33a92df-d576-4f3e-fa5b-2f4a86e1d72a"},"outputs":[],"source":["%cd /content/drive/MyDrive/NLP/machine_translation"]},{"cell_type":"markdown","metadata":{"id":"xz6JwxbK0mo1"},"source":["##1.Install library"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6542,"status":"ok","timestamp":1677694914963,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"},"user_tz":-420},"id":"nfXCevuj97q9","outputId":"074312bc-2a51-48da-f4ca-447ebc3ad0fe"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.8/462.8 KB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 KB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip -q install 'datasets==2.9.0' 'sentencepiece==0.1.97' 'sacrebleu==2.3.1'"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":4301,"status":"ok","timestamp":1677694919262,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"},"user_tz":-420},"id":"iOoEexf43Vqk"},"outputs":[],"source":["import os\n","import sys\n","import math\n","import copy\n","import heapq\n","import datetime\n","\n","from tqdm import tqdm\n","import numpy as np\n","\n","import sacrebleu\n","\n","import datasets\n","\n","import sentencepiece as spm\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"markdown","metadata":{"id":"Q5dJZutw0rug"},"source":["##2.Data Preparing\n","**IWSLT2015-EN-VI**"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1677694919263,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"},"user_tz":-420},"id":"Moxz37xr-QgU"},"outputs":[],"source":["class DataPreparing:\n","    def __init__(self, save_data_dir, source_lang, target_lang):\n","        self.save_data_dir = save_data_dir\n","        self.source_lang = source_lang\n","        self.target_lang = target_lang\n","    \n","    def download_dataset(self):\n","        if not(os.path.exists(self.save_data_dir)):\n","            print('Create Foler')\n","            os.mkdir(self.save_data_dir)\n","        if len(os.listdir(self.save_data_dir)) ==0:\n","            print('#1-Download Dataset')\n","            corpus = datasets.load_dataset(\"mt_eng_vietnamese\", \"iwslt2015-en-vi\")\n","            \n","            print('#2-Save Dataset')\n","            for data in ['train', 'validation', 'test']:\n","\n","                source_data, target_data = self.get_data(corpus[data])\n","\n","                print('Source lang: {} - {}: {}'.format(self.source_lang, data, len(source_data)))\n","                print('Target lang: {} - {}: {}'.format(self.target_lang, data, len(target_data)))\n","\n","                self.save_data(source_data, os.path.join(self.save_data_dir, data + '.' + self.source_lang))\n","                self.save_data(target_data, os.path.join(self.save_data_dir, data + '.' + self.target_lang))\n","\n","        else:\n","            print('Dataset exit!')\n","        \n","    def get_data(self, corpus):\n","        source_data = []\n","        target_data = []\n","        for data in corpus:\n","            source_data.append(data['translation'][self.source_lang])\n","            target_data.append(data['translation'][self.target_lang])\n","        return source_data, target_data\n","\n","    def save_data(self, data, save_path):\n","        print('=> Save data => Path: {}'.format(save_path))\n","        with open(save_path, 'w', encoding='utf-8') as f:\n","            f.write('\\n'.join(data))"]},{"cell_type":"markdown","metadata":{"id":"B9YpHW5Y04aB"},"source":["##3.SentencePiece Tokenization"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1677694919263,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"},"user_tz":-420},"id":"x_fHQHeU_4Zp"},"outputs":[],"source":["def train_sentencepiece(cfg, is_src=True):\n","    template = \"--input={} \\\n","                --pad_id={} \\\n","                --bos_id={} \\\n","                --eos_id={} \\\n","                --unk_id={} \\\n","                --model_prefix={} \\\n","                --vocab_size={} \\\n","                --character_coverage={} \\\n","                --model_type={}\"\n","    \n","    if is_src:\n","        train_file = f\"{cfg.data_dir}/train.{cfg.src_lang}\"\n","        model_prefix = f\"{cfg.sp_dir}/{cfg.src_model_prefix}\"\n","    else:\n","        train_file = f\"{cfg.data_dir}/train.{cfg.tgt_lang}\"\n","        model_prefix = f\"{cfg.sp_dir}/{cfg.tgt_model_prefix}\"\n","\n","    print(f\"===> Processing file: {train_file}\")\n","    if not os.path.isdir(cfg.sp_dir):\n","        os.mkdir(cfg.sp_dir)\n","\n","    sp_cfg = template.format(\n","        train_file,\n","        cfg.pad_id,\n","        cfg.sos_id,\n","        cfg.eos_id,\n","        cfg.unk_id,\n","        model_prefix,\n","        cfg.sp_vocab_size,\n","        cfg.character_coverage,\n","        cfg.model_type)\n","    \n","    spm.SentencePieceTrainer.Train(sp_cfg)"]},{"cell_type":"markdown","metadata":{"id":"rM31YJgZ1K8U"},"source":["##4.Dataloader"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1677694919263,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"},"user_tz":-420},"id":"ZnXQ_jD61pgl"},"outputs":[],"source":["class NMTDataset(Dataset):\n","    def __init__(self, cfg, data_type=\"train\"):\n","        super().__init__()\n","        self.cfg = cfg\n","\n","        self.sp_src, self.sp_tgt = self.load_sp_tokenizer()\n","        self.src_texts, self.tgt_texts = self.read_data(data_type)\n","\n","        src_tokenized_sequences = self.texts_to_sequences(self.src_texts, True)\n","        tgt_input_tokenized_sequences, tgt_output_tokenized_sequences = self.texts_to_sequences(self.tgt_texts, False)\n","\n","        self.src_data = torch.LongTensor(src_tokenized_sequences)\n","        self.input_tgt_data = torch.LongTensor(tgt_input_tokenized_sequences)\n","        self.output_tgt_data = torch.LongTensor(tgt_output_tokenized_sequences)\n","\n","    def read_data(self, data_type):\n","        print(f\"===> Load data from: {self.cfg.data_dir}/{data_type}.{self.cfg.src_lang}\")\n","        with open(f\"{self.cfg.data_dir}/{data_type}.{self.cfg.src_lang}\", 'r') as f:\n","            src_texts = f.readlines()\n","\n","        print(f\"===> Load data from: {self.cfg.data_dir}/{data_type}.{self.cfg.tgt_lang}\")\n","        with open(f\"{self.cfg.data_dir}/{data_type}.{self.cfg.tgt_lang}\", 'r') as f:\n","            trg_texts = f.readlines()\n","        \n","        return src_texts, trg_texts\n","    \n","    def load_sp_tokenizer(self):\n","        sp_src = spm.SentencePieceProcessor()\n","        sp_src.Load(f\"{self.cfg.sp_dir}/{self.cfg.src_model_prefix}.model\")\n","\n","        sp_tgt = spm.SentencePieceProcessor()\n","        sp_tgt.Load(f\"{self.cfg.sp_dir}/{self.cfg.tgt_model_prefix}.model\")\n","\n","        return sp_src, sp_tgt\n","    \n","    def texts_to_sequences(self, texts, is_src=True):\n","        if is_src:\n","            src_tokenized_sequences = []\n","            for text in tqdm(texts):\n","                tokenized = self.sp_src.EncodeAsIds(text.strip())\n","                src_tokenized_sequences.append(\n","                    pad_or_truncate([self.cfg.sos_id] + tokenized + [self.cfg.eos_id], self.cfg.seq_len, self.cfg.pad_id)\n","                )\n","            return src_tokenized_sequences\n","        else:\n","            tgt_input_tokenized_sequences = []\n","            tgt_output_tokenized_sequences = []\n","            for text in tqdm(texts):\n","                tokenized = self.sp_tgt.EncodeAsIds(text.strip())\n","                tgt_input = [self.cfg.sos_id] + tokenized\n","                tgt_output = tokenized + [self.cfg.eos_id]\n","                tgt_input_tokenized_sequences.append(pad_or_truncate(tgt_input, self.cfg.seq_len, self.cfg.pad_id))\n","                tgt_output_tokenized_sequences.append(pad_or_truncate(tgt_output, self.cfg.seq_len, self.cfg.pad_id))\n","\n","            return tgt_input_tokenized_sequences, tgt_output_tokenized_sequences\n","\n","    def __getitem__(self, idx):\n","        return self.src_data[idx], self.input_tgt_data[idx], self.output_tgt_data[idx]\n","\n","    def __len__(self):\n","        return np.shape(self.src_data)[0]\n","\n","def pad_or_truncate(tokenized_sequence, seq_len, pad_id):\n","    if len(tokenized_sequence) < seq_len:\n","        left = seq_len - len(tokenized_sequence)\n","        padding = [pad_id] * left\n","        tokenized_sequence += padding\n","    else:\n","        tokenized_sequence = tokenized_sequence[:seq_len]\n","    return tokenized_sequence\n","\n","def get_data_loader(cfg, data_type='train'):\n","    dataset = NMTDataset(cfg, data_type)\n","\n","    if data_type == 'train':\n","        shuffle = True\n","    else:\n","        shuffle = False\n","\n","    dataloader = DataLoader(dataset, batch_size=cfg.batch_size, shuffle=shuffle)\n","\n","    return dataset, dataloader"]},{"cell_type":"markdown","metadata":{"id":"Cvx0Mu7CmIfg"},"source":["##5.Transformer Model\n","Ref: https://pytorch.org/tutorials/beginner/translation_transformer.html"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1677694919263,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"},"user_tz":-420},"id":"ol7eNRBWmMID"},"outputs":[],"source":["class MultiheadAttention(nn.Module):\n","    def __init__(self, d_model, num_heads, drop_out=0.1):\n","        super().__init__()\n","        self.inf = 1e9\n","\n","        self.d_model = d_model\n","        self.num_heads = num_heads\n","        self.d_k = d_model // num_heads\n","\n","        # W^Q, W^K, W^V in the paper\n","        self.w_q = nn.Linear(d_model, d_model)\n","        self.w_k = nn.Linear(d_model, d_model)\n","        self.w_v = nn.Linear(d_model, d_model)\n","\n","        self.dropout = nn.Dropout(drop_out)\n","        self.attn_softmax = nn.Softmax(dim=-1)\n","\n","        # Final output linear transformation\n","        self.w_0 = nn.Linear(d_model, d_model)\n","\n","    def forward(self, q, k, v, mask=None):\n","        input_shape = q.shape\n","\n","        # Linear calculation +  split into num_heads\n","        q = self.w_q(q).view(input_shape[0], -1, self.num_heads, self.d_k) # (B, L, num_heads, d_k)\n","        k = self.w_k(k).view(input_shape[0], -1, self.num_heads, self.d_k) # (B, L, num_heads, d_k)\n","        v = self.w_v(v).view(input_shape[0], -1, self.num_heads, self.d_k) # (B, L, num_heads, d_k)\n","\n","        # For convenience, convert all tensors in size (B, num_heads, L, d_k)\n","        q = q.transpose(1, 2)\n","        k = k.transpose(1, 2)\n","        v = v.transpose(1, 2)\n","\n","        # Conduct self-attention\n","        attn_values = self.self_attention(q, k, v, mask=mask) # (B, num_heads, L, d_k)\n","        concat_output = attn_values.transpose(1, 2)\\\n","            .contiguous().view(input_shape[0], -1, self.d_model) # (B, L, d_model)\n","\n","        return self.w_0(concat_output)\n","\n","    def self_attention(self, q, k, v, mask=None):\n","        # Calculate attention scores with scaled dot-product attention\n","        attn_scores = torch.matmul(q, k.transpose(-2, -1)) # (B, num_heads, L, L)\n","        attn_scores = attn_scores / math.sqrt(self.d_k)\n","\n","        # If there is a mask, make masked spots -INF\n","        if mask is not None:\n","            mask = mask.unsqueeze(1) # (B, 1, L) => (B, 1, 1, L) or (B, L, L) => (B, 1, L, L)\n","            attn_scores = attn_scores.masked_fill_(mask == 0, -1 * self.inf)\n","\n","        # Softmax and multiplying K to calculate attention value\n","        attn_distribs = self.attn_softmax(attn_scores)\n","\n","        attn_distribs = self.dropout(attn_distribs)\n","        attn_values = torch.matmul(attn_distribs, v) # (B, num_heads, L, d_k)\n","\n","        return attn_values\n","\n","class FeedFowardLayer(nn.Module):\n","    def __init__(self, d_model, d_ff, drop_out=0.1):\n","        super().__init__()\n","        self.linear_1 = nn.Linear(d_model, d_ff, bias=True)\n","        self.relu = nn.ReLU()\n","        self.linear_2 = nn.Linear(d_ff, d_model, bias=True)\n","        self.dropout = nn.Dropout(drop_out)\n","\n","    def forward(self, x):\n","        x = self.relu(self.linear_1(x)) # (B, L, d_ff)\n","        x = self.dropout(x)\n","        x = self.linear_2(x) # (B, L, d_model)\n","\n","        return x\n","\n","\n","class LayerNormalization(nn.Module):\n","    def __init__(self, d_model, eps=1e-6):\n","        super().__init__()\n","        self.eps = eps\n","        self.layer = nn.LayerNorm([d_model], elementwise_affine=True, eps=self.eps)\n","\n","    def forward(self, x):\n","        x = self.layer(x)\n","\n","        return x\n","\n","class PositionalEncoder(nn.Module):\n","    def __init__(self, seq_len, d_model, device):\n","        super().__init__()\n","        self.seq_len = seq_len\n","        self.d_model = d_model\n","        # Make initial positional encoding matrix with 0\n","        pe_matrix= torch.zeros(seq_len, d_model) # (L, d_model)\n","\n","        # Calculating position encoding values\n","        for pos in range(seq_len):\n","            for i in range(d_model):\n","                if i % 2 == 0:\n","                    pe_matrix[pos, i] = math.sin(pos / (10000 ** (2 * i / d_model)))\n","                elif i % 2 == 1:\n","                    pe_matrix[pos, i] = math.cos(pos / (10000 ** (2 * i / d_model)))\n","\n","        pe_matrix = pe_matrix.unsqueeze(0) # (1, L, d_model)\n","        self.positional_encoding = pe_matrix.to(device=device).requires_grad_(False)\n","\n","    def forward(self, x):\n","        x = x * math.sqrt(self.d_model) # (B, L, d_model)\n","        x = x + self.positional_encoding # (B, L, d_model)\n","\n","        return x\n","\n","class EncoderLayer(nn.Module):\n","    def __init__(self, d_model, num_heads, d_ff, drop_out=0.1):\n","        super().__init__()\n","        self.layer_norm_1 = LayerNormalization(d_model)\n","        self.multihead_attention = MultiheadAttention(d_model, num_heads, drop_out)\n","        self.drop_out_1 = nn.Dropout(drop_out)\n","\n","        self.layer_norm_2 = LayerNormalization(d_model)\n","        self.feed_forward = FeedFowardLayer(d_model, d_ff, drop_out)\n","        self.drop_out_2 = nn.Dropout(drop_out)\n","\n","    def forward(self, x, e_mask):\n","        x_1 = self.layer_norm_1(x) # (B, L, d_model)\n","        x = x + self.drop_out_1(\n","            self.multihead_attention(x_1, x_1, x_1, mask=e_mask)\n","        ) # (B, L, d_model)\n","\n","        x_2 = self.layer_norm_2(x) # (B, L, d_model)\n","        x = x + self.drop_out_2(self.feed_forward(x_2)) # (B, L, d_model)\n","\n","        return x # (B, L, d_model)\n","\n","class DecoderLayer(nn.Module):\n","    def __init__(self, d_model, num_heads, d_ff, drop_out=0.1):\n","        super().__init__()\n","        self.layer_norm_1 = LayerNormalization(d_model)\n","        self.masked_multihead_attention = MultiheadAttention(d_model, num_heads, drop_out)\n","        self.drop_out_1 = nn.Dropout(drop_out)\n","\n","        self.layer_norm_2 = LayerNormalization(d_model)\n","        self.multihead_attention = MultiheadAttention(d_model, num_heads, drop_out)\n","        self.drop_out_2 = nn.Dropout(drop_out)\n","\n","        self.layer_norm_3 = LayerNormalization(d_model)\n","        self.feed_forward = FeedFowardLayer(d_model, d_ff, drop_out)\n","        self.drop_out_3 = nn.Dropout(drop_out)\n","\n","    def forward(self, x, e_output, e_mask,  d_mask):\n","        x_1 = self.layer_norm_1(x) # (B, L, d_model)\n","        x = x + self.drop_out_1(\n","            self.masked_multihead_attention(x_1, x_1, x_1, mask=d_mask)\n","        ) # (B, L, d_model)\n","        x_2 = self.layer_norm_2(x) # (B, L, d_model)\n","        x = x + self.drop_out_2(\n","            self.multihead_attention(x_2, e_output, e_output, mask=e_mask)\n","        ) # (B, L, d_model)\n","        x_3 = self.layer_norm_3(x) # (B, L, d_model)\n","        x = x + self.drop_out_3(self.feed_forward(x_3)) # (B, L, d_model)\n","\n","        return x # (B, L, d_model)\n","\n","class Encoder(nn.Module):\n","    def __init__(self, num_layers, d_model, num_heads, d_ff, drop_out=0.1):\n","        super().__init__()\n","        self.num_layers = num_layers\n","        self.layers = nn.ModuleList(\n","            [EncoderLayer(d_model, num_heads, d_ff, drop_out) for i in range(num_layers)]\n","        )\n","        self.layer_norm = LayerNormalization(d_model)\n","\n","    def forward(self, x, e_mask):\n","        for i in range(self.num_layers):\n","            x = self.layers[i](x, e_mask)\n","\n","        return self.layer_norm(x)\n","    \n","class Decoder(nn.Module):\n","    def __init__(self, num_layers, d_model, num_heads, d_ff, drop_out):\n","        super().__init__()\n","        self.num_layers = num_layers\n","        self.layers = nn.ModuleList(\n","            [DecoderLayer(d_model, num_heads, d_ff, drop_out) for i in range(num_layers)]\n","        )\n","        self.layer_norm = LayerNormalization(d_model)\n","\n","    def forward(self, x, e_output, e_mask, d_mask):\n","        for i in range(self.num_layers):\n","            x = self.layers[i](x, e_output, e_mask, d_mask)\n","\n","        return self.layer_norm(x)\n","\n","class Transformer(nn.Module):\n","    def __init__(self, cfg):\n","        super().__init__()\n","        self.cfg = cfg\n","\n","        self.src_embedding = nn.Embedding(self.cfg.sp_vocab_size, self.cfg.d_model)\n","        self.tgt_embedding = nn.Embedding(self.cfg.sp_vocab_size, self.cfg.d_model)\n","        self.positional_encoder = PositionalEncoder(\n","            self.cfg.seq_len, \n","            self.cfg.d_model, \n","            self.cfg.device\n","        )\n","        self.encoder = Encoder(\n","            self.cfg.num_layers, \n","            self.cfg.d_model, \n","            self.cfg.num_heads, \n","            self.cfg.d_ff, \n","            self.cfg.drop_out\n","        )\n","        self.decoder = Decoder(\n","            self.cfg.num_layers, \n","            self.cfg.d_model, \n","            self.cfg.num_heads, \n","            self.cfg.d_ff, \n","            self.cfg.drop_out\n","        )\n","        self.output_linear = nn.Linear(self.cfg.d_model, self.cfg.sp_vocab_size)\n","        self.softmax = nn.LogSoftmax(dim=-1)\n","\n","    def forward(self, src_input, tgt_input, e_mask=None, d_mask=None):\n","        src_input = self.src_embedding(src_input) # (B, L) => (B, L, d_model)\n","        tgt_input = self.tgt_embedding(tgt_input) # (B, L) => (B, L, d_model)\n","        src_input = self.positional_encoder(src_input) # (B, L, d_model) => (B, L, d_model)\n","        tgt_input = self.positional_encoder(tgt_input) # (B, L, d_model) => (B, L, d_model)\n","\n","        e_output = self.encoder(src_input, e_mask) # (B, L, d_model)\n","        d_output = self.decoder(tgt_input, e_output, e_mask, d_mask) # (B, L, d_model)\n","\n","        output = self.softmax(self.output_linear(d_output)) # (B, L, d_model) => # (B, L, trg_vocab_size)\n","\n","        return output"]},{"cell_type":"markdown","metadata":{"id":"dUUJaH8GovIj"},"source":["##7.Trainer"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1677694920987,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"},"user_tz":-420},"id":"mcCFypjcowwr"},"outputs":[],"source":["class Trainer():\n","    def __init__(self, cfg, is_train=True, load_ckpt=True):\n","        self.cfg = cfg\n","        \n","        print(\"Loading Transformer model & Adam optimizer...\")\n","        self.model = Transformer(self.cfg).to(self.cfg.device)\n","\n","        self.optim = torch.optim.Adam(self.model.parameters(), lr=self.cfg.learning_rate)\n","\n","        self.best_loss = 100.0\n","        if load_ckpt:\n","            print(\"Loading checkpoint...\")\n","            checkpoint = torch.load(f\"{self.cfg.ckpt_dir}/{self.cfg.ckpt_name}\", map_location=self.cfg.device)\n","            self.model.load_state_dict(checkpoint['model_state_dict'])\n","            self.optim.load_state_dict(checkpoint['optim_state_dict'])\n","            self.best_loss = checkpoint['loss']\n","        else:\n","            print(\"Initializing the model...\")\n","            for p in self.model.parameters():\n","                if p.dim() > 1:\n","                    nn.init.xavier_uniform_(p)\n","        \n","        # Prepare Tokenizer\n","        self.prepare_tokenizer()\n","\n","        if is_train:\n","            # Load loss function\n","            print(\"Loading loss function...\")\n","            self.criterion = nn.NLLLoss()\n","\n","            # Load dataloaders\n","            print(\"Loading dataloaders...\")\n","            self.train_dataset, self.train_loader = get_data_loader(self.cfg, 'train')\n","            self.valid_dataset, self.valid_loader = get_data_loader(self.cfg, 'validation')\n","\n","        else:\n","            if os.path.exists(f\"{self.cfg.ckpt_dir}/{self.cfg.ckpt_name}\"):\n","                print(\"Loading sentencepiece tokenizer...\")\n","                self.sp_src = spm.SentencePieceProcessor()\n","                self.sp_tgt = spm.SentencePieceProcessor()\n","                self.sp_src.Load(f\"{self.cfg.sp_dir}/{self.cfg.src_model_prefix}.model\")\n","                self.sp_tgt.Load(f\"{self.cfg.sp_dir}/{self.cfg.tgt_model_prefix}.model\")\n","            else:\n","                print(\"Checkpoint path not exits...\")\n","        \n","        print(\"Setting finished.\")\n","    \n","    def prepare_tokenizer(self):\n","        if not os.path.isdir(self.cfg.sp_dir):\n","            print('Training sentencepiece tokenizer...')\n","            train_sentencepiece(self.cfg, is_src=True)\n","            train_sentencepiece(self.cfg, is_src=False)\n","        else:\n","            print('Tokenization already...')\n","\n","    def train(self):\n","        print(\"Training...\")\n","\n","        for epoch in range(1, self.cfg.num_epochs+1):\n","            print(f\"#################### Epoch: {epoch} ####################\")\n","\n","            self.model.train()\n","            train_losses = []\n","            start_time = datetime.datetime.now()\n","\n","            bar = tqdm(enumerate(self.train_loader), total=len(self.train_loader), desc='TRAINING')\n","\n","            for batch_idx, batch in bar:\n","                src_input, tgt_input, tgt_output = batch\n","                src_input, tgt_input, tgt_output = src_input.to(self.cfg.device), tgt_input.to(self.cfg.device), tgt_output.to(self.cfg.device)\n","\n","                e_mask, d_mask = self.create_mask(src_input, tgt_input)\n","\n","                logits = self.model(src_input, tgt_input, e_mask, d_mask)\n","\n","                self.optim.zero_grad()\n","\n","                loss = self.criterion(\n","                    logits.view(-1, logits.shape[-1]),\n","                    tgt_output.reshape(-1)\n","                )\n","                \n","                loss.backward()\n","                self.optim.step()\n","\n","                train_losses.append(loss.item())\n","                \n","                del src_input, tgt_input, tgt_output, e_mask, d_mask, logits\n","                torch.cuda.empty_cache()\n","\n","                bar.set_postfix(TRAIN=\"Epoch {} - Batch_Loss {:.2f} - Train_Loss {:.2f} - Best_Valid_Loss {:.2f}\".format(\n","                    epoch,\n","                    loss.item(),\n","                    np.mean(train_losses),\n","                    self.best_loss\n","                    )\n","                )\n","\n","            end_time = datetime.datetime.now()\n","            training_time = end_time - start_time\n","\n","            mean_train_loss = np.mean(train_losses)\n","            print(f\"Train loss: {mean_train_loss} || Time: {training_time} secs\")\n","\n","            valid_loss, valid_time = self.validation()\n","            \n","            if valid_loss < self.best_loss:\n","                if not os.path.exists(self.cfg.ckpt_dir):\n","                    os.mkdir(self.cfg.ckpt_dir)\n","                    \n","                self.best_loss = valid_loss\n","                state_dict = {\n","                    'model_state_dict': self.model.state_dict(),\n","                    'optim_state_dict': self.optim.state_dict(),\n","                    'loss': self.best_loss\n","                }\n","                torch.save(state_dict, f\"{self.cfg.ckpt_dir}/{self.cfg.ckpt_name}\")\n","                print(f\"***** Current best checkpoint is saved. *****\")\n","\n","            print(f\"Best valid loss: {self.best_loss}\")\n","            print(f\"Valid loss: {valid_loss} || One epoch training time: {valid_time}\")\n","\n","        print(f\"Training finished!\")\n","        \n","    def validation(self):\n","        self.model.eval()\n","        \n","        valid_losses = []\n","        start_time = datetime.datetime.now()\n","\n","        with torch.no_grad():\n","            bar = tqdm(enumerate(self.valid_loader), total=len(self.valid_loader), desc='VALIDATIION')\n","            for batch_idx, batch in bar:\n","                src_input, tgt_input, tgt_output = batch\n","                src_input, tgt_input, tgt_output = src_input.to(self.cfg.device), tgt_input.to(self.cfg.device), tgt_output.to(self.cfg.device)\n","\n","                e_mask, d_mask = self.create_mask(src_input, tgt_input)\n","\n","                logits = self.model(src_input, tgt_input, e_mask, d_mask)\n","\n","                loss = self.criterion(\n","                    logits.view(-1, logits.shape[-1]),\n","                    tgt_output.reshape(-1)\n","                )\n","\n","                valid_losses.append(loss.item())\n","\n","                bar.set_postfix(TRAIN=\"Batch_Loss {:.2f} - Valid_Loss {:.2f}\".format(\n","                    loss.item(),\n","                    np.mean(valid_losses)\n","                    )\n","                )\n","\n","                del src_input, tgt_input, tgt_output, e_mask, d_mask, logits\n","                torch.cuda.empty_cache()\n","\n","        end_time = datetime.datetime.now()\n","        validation_time = end_time - start_time\n","        \n","        mean_valid_loss = np.mean(valid_losses)\n","        \n","        return mean_valid_loss, f\"{validation_time} secs\"\n","\n","    def inference(self, input_sentence):\n","        self.model.eval()\n","\n","        print(\"Preprocessing input sentence...\")\n","        tokenized = self.sp_src.EncodeAsIds(input_sentence)\n","        src_data = torch.LongTensor(\n","            pad_or_truncate([self.cfg.sos_id] + tokenized + [self.cfg.eos_id], self.cfg.seq_len, self.cfg.pad_id)\n","        ).unsqueeze(0).to(self.cfg.device)\n","\n","        e_mask = (src_data != self.cfg.pad_id).unsqueeze(1).to(self.cfg.device) # (1, 1, L)\n","\n","        start_time = datetime.datetime.now()\n","\n","        print(\"Encoding input sentence...\")\n","        src_data = self.model.src_embedding(src_data)\n","        src_data = self.model.positional_encoder(src_data)\n","        e_output = self.model.encoder(src_data, e_mask) # (1, L, d_model)\n","\n","        result = self.greedy_search(e_output, e_mask)\n","\n","        end_time = datetime.datetime.now()\n","\n","        total_inference_time = end_time - start_time\n","\n","        print(f\"Input: {input_sentence}\")\n","        print(f\"Result: {result}\")\n","        print(f\"Inference finished! || Total inference time: {total_inference_time}secs\")\n","        return result\n","        \n","    def greedy_search(self, e_output, e_mask):\n","        last_words = torch.LongTensor([self.cfg.pad_id] * self.cfg.seq_len).to(self.cfg.device) # (L)\n","        last_words[0] = self.cfg.sos_id # (L)\n","        cur_len = 1\n","\n","        for i in range(self.cfg.seq_len):\n","            d_mask = (last_words.unsqueeze(0) != self.cfg.pad_id).unsqueeze(1).to(self.cfg.device) # (1, 1, L)\n","            nopeak_mask = torch.ones([1, self.cfg.seq_len, self.cfg.seq_len], dtype=torch.bool).to(self.cfg.device)  # (1, L, L)\n","            nopeak_mask = torch.tril(nopeak_mask)  # (1, L, L) to triangular shape\n","            d_mask = d_mask & nopeak_mask  # (1, L, L) padding false\n","\n","            tgt_embedded = self.model.tgt_embedding(last_words.unsqueeze(0))\n","            tgt_positional_encoded = self.model.positional_encoder(tgt_embedded)\n","            decoder_output = self.model.decoder(\n","                tgt_positional_encoded,\n","                e_output,\n","                e_mask,\n","                d_mask\n","            ) # (1, L, d_model)\n","\n","            output = self.model.softmax(\n","                self.model.output_linear(decoder_output)\n","            ) # (1, L, trg_vocab_size)\n","\n","            output = torch.argmax(output, dim=-1) # (1, L)\n","            last_word_id = output[0][i].item()\n","            \n","            if i < self.cfg.seq_len-1:\n","                last_words[i+1] = last_word_id\n","                cur_len += 1\n","            \n","            if last_word_id == self.cfg.eos_id:\n","                break\n","\n","        if last_words[-1].item() == self.cfg.pad_id:\n","            decoded_output = last_words[1:cur_len].tolist()\n","        else:\n","            decoded_output = last_words[1:].tolist()\n","        decoded_output = self.sp_tgt.decode_ids(decoded_output)\n","        \n","        return decoded_output\n","\n","    def create_mask(self, src_input, tgt_input):\n","        e_mask = (src_input != self.cfg.pad_id).unsqueeze(1)  # (B, 1, L)\n","        d_mask = (tgt_input != self.cfg.pad_id).unsqueeze(1)  # (B, 1, L)\n","\n","        nopeak_mask = torch.ones([1, self.cfg.seq_len, self.cfg.seq_len], dtype=torch.bool)  # (1, L, L)\n","        nopeak_mask = torch.tril(nopeak_mask).to(self.cfg.device)  # (1, L, L) to triangular shape\n","        d_mask = d_mask & nopeak_mask  # (B, L, L) padding false\n","\n","        return e_mask, d_mask"]},{"cell_type":"markdown","metadata":{"id":"8pqIEejha7tt"},"source":["##8.Training"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":581,"status":"ok","timestamp":1677694932746,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"},"user_tz":-420},"id":"CmX2WOFqrpQ-"},"outputs":[],"source":["class BaseConfig:\n","    \"\"\" base Encoder Decoder config \"\"\"\n","\n","    def __init__(self, **kwargs):\n","        for k, v in kwargs.items():\n","            setattr(self, k, v)\n","\n","class NMTConfig(BaseConfig):\n","    # Dataset\n","    data_dir = './transformer/data'\n","    src_lang = 'vi'\n","    tgt_lang = 'en'\n","\n","    # Tokenizer\n","    sp_dir = data_dir + '/sp'\n","    pad_id = 0\n","    sos_id = 1\n","    eos_id = 2\n","    unk_id = 3\n","    src_model_prefix = 'sp_' + src_lang\n","    tgt_model_prefix = 'sp_' + tgt_lang\n","    sp_vocab_size = 10000\n","    character_coverage = 1.0\n","    model_type = 'unigram'\n","\n","    # Model\n","    num_heads = 8\n","    num_layers = 6\n","    d_model = 512\n","    d_ff = 2048\n","    drop_out = 0.1\n","\n","    # Training\n","    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","    learning_rate = 1e-4\n","    batch_size = 256\n","    seq_len = 150\n","    num_epochs = 50\n","    ckpt_dir = './transformer'\n","    ckpt_name = 'best_ckpt.tar'"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1677693587721,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"},"user_tz":-420},"id":"wVmHNIxks6z-"},"outputs":[],"source":["cfg = NMTConfig()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JxLSAsdbtD7j"},"outputs":[],"source":["data_pre = DataPreparing(cfg.data_dir, cfg.src_lang, cfg.tgt_lang)\n","data_pre.download_dataset()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":58744,"status":"error","timestamp":1677310650234,"user":{"displayName":"1Byte Software AI team 2","userId":"13646169708796052523"},"user_tz":-420},"id":"6K7bBbwvimSU","outputId":"05becfff-3985-4728-a471-7a58d2360d9b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading Transformer model & Adam optimizer...\n","Initializing the model...\n","Training sentencepiece tokenizer...\n","===> Processing file: ./data/train.vi\n","===> Processing file: ./data/train.en\n","Loading loss function...\n","Loading dataloaders...\n","===> Load data from: ./data/train.vi\n","===> Load data from: ./data/train.en\n"]},{"name":"stderr","output_type":"stream","text":["\n","  0%|          | 0/133317 [00:00<?, ?it/s]\u001b[A\n","  2%|▏         | 3075/133317 [00:00<00:04, 30735.01it/s]\u001b[A\n","  5%|▍         | 6149/133317 [00:00<00:04, 29246.62it/s]\u001b[A\n","  7%|▋         | 9359/133317 [00:00<00:04, 30507.69it/s]\u001b[A\n","  9%|▉         | 12462/133317 [00:00<00:03, 30708.61it/s]\u001b[A\n"," 12%|█▏        | 15537/133317 [00:00<00:03, 30134.38it/s]\u001b[A\n"," 14%|█▍        | 18663/133317 [00:00<00:03, 30507.89it/s]\u001b[A\n"," 16%|█▋        | 21718/133317 [00:00<00:04, 22750.12it/s]\u001b[A\n"," 19%|█▉        | 25011/133317 [00:00<00:04, 25350.11it/s]\u001b[A\n"," 21%|██        | 28184/133317 [00:01<00:03, 27055.82it/s]\u001b[A\n"," 24%|██▎       | 31413/133317 [00:01<00:03, 28502.50it/s]\u001b[A\n"," 26%|██▌       | 34427/133317 [00:01<00:03, 28965.19it/s]\u001b[A\n"," 28%|██▊       | 37872/133317 [00:01<00:03, 30542.41it/s]\u001b[A\n"," 31%|███       | 41012/133317 [00:01<00:03, 30562.96it/s]\u001b[A\n"," 33%|███▎      | 44128/133317 [00:01<00:02, 30577.39it/s]\u001b[A\n"," 35%|███▌      | 47228/133317 [00:01<00:02, 30406.98it/s]\u001b[A\n"," 38%|███▊      | 50420/133317 [00:01<00:02, 30849.67it/s]\u001b[A\n"," 40%|████      | 53578/133317 [00:01<00:02, 31063.62it/s]\u001b[A\n"," 43%|████▎     | 56700/133317 [00:01<00:02, 30745.68it/s]\u001b[A\n"," 45%|████▍     | 59976/133317 [00:02<00:02, 31338.38it/s]\u001b[A\n"," 47%|████▋     | 63119/133317 [00:02<00:02, 31308.79it/s]\u001b[A\n"," 50%|████▉     | 66257/133317 [00:02<00:02, 30651.06it/s]\u001b[A\n"," 52%|█████▏    | 69600/133317 [00:02<00:02, 31461.50it/s]\u001b[A\n"," 55%|█████▍    | 72753/133317 [00:02<00:01, 31398.09it/s]\u001b[A\n"," 57%|█████▋    | 75901/133317 [00:02<00:01, 31418.92it/s]\u001b[A\n"," 59%|█████▉    | 79215/133317 [00:02<00:01, 31929.07it/s]\u001b[A\n"," 62%|██████▏   | 82411/133317 [00:02<00:01, 31077.36it/s]\u001b[A\n"," 64%|██████▍   | 85526/133317 [00:02<00:01, 30881.41it/s]\u001b[A\n"," 66%|██████▋   | 88619/133317 [00:02<00:01, 30718.46it/s]\u001b[A\n"," 69%|██████▉   | 91723/133317 [00:03<00:01, 30810.82it/s]\u001b[A\n"," 71%|███████   | 94918/133317 [00:03<00:01, 31145.70it/s]\u001b[A\n"," 74%|███████▎  | 98035/133317 [00:03<00:01, 30470.48it/s]\u001b[A\n"," 76%|███████▌  | 101274/133317 [00:03<00:01, 31031.43it/s]\u001b[A\n"," 78%|███████▊  | 104576/133317 [00:03<00:00, 31612.59it/s]\u001b[A\n"," 81%|████████  | 107742/133317 [00:03<00:00, 31064.00it/s]\u001b[A\n"," 83%|████████▎ | 111010/133317 [00:03<00:00, 31537.31it/s]\u001b[A\n"," 86%|████████▌ | 114168/133317 [00:03<00:00, 31133.14it/s]\u001b[A\n"," 88%|████████▊ | 117285/133317 [00:04<00:00, 19451.06it/s]\u001b[A\n"," 90%|█████████ | 120588/133317 [00:04<00:00, 22273.39it/s]\u001b[A\n"," 93%|█████████▎| 123509/133317 [00:04<00:00, 23860.98it/s]\u001b[A\n"," 95%|█████████▌| 126699/133317 [00:04<00:00, 25840.84it/s]\u001b[A\n"," 97%|█████████▋| 129715/133317 [00:04<00:00, 26964.42it/s]\u001b[A\n","100%|██████████| 133317/133317 [00:04<00:00, 28972.57it/s]\n","100%|██████████| 133317/133317 [00:05<00:00, 25941.78it/s]\n"]},{"name":"stdout","output_type":"stream","text":["===> Load data from: ./data/validation.vi\n","===> Load data from: ./data/validation.en\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1268/1268 [00:00<00:00, 28964.36it/s]\n","100%|██████████| 1268/1268 [00:00<00:00, 28042.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Setting finished.\n","Training...\n","#################### Epoch: 1 ####################\n"]},{"name":"stderr","output_type":"stream","text":["TRAINING: 100%|██████████| 521/521 [11:29<00:00,  1.32s/it, TRAIN=Epoch 1 - Batch_Loss 0.85 - Train_Loss 1.24 - Best_Valid_Loss 100.00]\n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 1.2430569899059303 || Time: 0:11:29.887747 secs\n"]},{"name":"stderr","output_type":"stream","text":["VALIDATIION: 100%|██████████| 5/5 [00:01<00:00,  3.28it/s, TRAIN=Batch_Loss 0.97 - Valid_Loss 0.87]\n"]},{"name":"stdout","output_type":"stream","text":["***** Current best checkpoint is saved. *****\n","Best valid loss: 0.868162739276886\n","Valid loss: 0.868162739276886 || One epoch training time: 0:00:01.527788 secs\n","#################### Epoch: 2 ####################\n"]},{"name":"stderr","output_type":"stream","text":["TRAINING: 100%|██████████| 521/521 [11:21<00:00,  1.31s/it, TRAIN=Epoch 2 - Batch_Loss 0.75 - Train_Loss 0.78 - Best_Valid_Loss 0.87]\n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 0.7764160604486081 || Time: 0:11:21.375193 secs\n"]},{"name":"stderr","output_type":"stream","text":["VALIDATIION: 100%|██████████| 5/5 [00:01<00:00,  3.28it/s, TRAIN=Batch_Loss 0.86 - Valid_Loss 0.77]\n"]},{"name":"stdout","output_type":"stream","text":["***** Current best checkpoint is saved. *****\n","Best valid loss: 0.7656753659248352\n","Valid loss: 0.7656753659248352 || One epoch training time: 0:00:01.525868 secs\n","#################### Epoch: 3 ####################\n"]},{"name":"stderr","output_type":"stream","text":["TRAINING: 100%|██████████| 521/521 [11:21<00:00,  1.31s/it, TRAIN=Epoch 3 - Batch_Loss 0.60 - Train_Loss 0.70 - Best_Valid_Loss 0.77]\n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 0.6958415253148655 || Time: 0:11:21.399198 secs\n"]},{"name":"stderr","output_type":"stream","text":["VALIDATIION: 100%|██████████| 5/5 [00:01<00:00,  3.27it/s, TRAIN=Batch_Loss 0.78 - Valid_Loss 0.68]\n"]},{"name":"stdout","output_type":"stream","text":["***** Current best checkpoint is saved. *****\n","Best valid loss: 0.6789168834686279\n","Valid loss: 0.6789168834686279 || One epoch training time: 0:00:01.532162 secs\n","#################### Epoch: 4 ####################\n"]},{"name":"stderr","output_type":"stream","text":["TRAINING: 100%|██████████| 521/521 [11:21<00:00,  1.31s/it, TRAIN=Epoch 4 - Batch_Loss 0.60 - Train_Loss 0.62 - Best_Valid_Loss 0.68]\n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 0.6201292650484536 || Time: 0:11:21.657058 secs\n"]},{"name":"stderr","output_type":"stream","text":["VALIDATIION: 100%|██████████| 5/5 [00:01<00:00,  3.29it/s, TRAIN=Batch_Loss 0.71 - Valid_Loss 0.61]\n"]},{"name":"stdout","output_type":"stream","text":["***** Current best checkpoint is saved. *****\n","Best valid loss: 0.6060018181800843\n","Valid loss: 0.6060018181800843 || One epoch training time: 0:00:01.526685 secs\n","#################### Epoch: 5 ####################\n"]},{"name":"stderr","output_type":"stream","text":["TRAINING: 100%|██████████| 521/521 [11:21<00:00,  1.31s/it, TRAIN=Epoch 5 - Batch_Loss 0.55 - Train_Loss 0.56 - Best_Valid_Loss 0.61]\n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 0.5570614205784166 || Time: 0:11:21.496909 secs\n"]},{"name":"stderr","output_type":"stream","text":["VALIDATIION: 100%|██████████| 5/5 [00:01<00:00,  3.28it/s, TRAIN=Batch_Loss 0.65 - Valid_Loss 0.55]\n"]},{"name":"stdout","output_type":"stream","text":["***** Current best checkpoint is saved. *****\n","Best valid loss: 0.5502584457397461\n","Valid loss: 0.5502584457397461 || One epoch training time: 0:00:01.528289 secs\n","#################### Epoch: 6 ####################\n"]},{"name":"stderr","output_type":"stream","text":["TRAINING: 100%|██████████| 521/521 [11:21<00:00,  1.31s/it, TRAIN=Epoch 6 - Batch_Loss 0.47 - Train_Loss 0.51 - Best_Valid_Loss 0.55]\n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 0.5061275197082198 || Time: 0:11:21.550687 secs\n"]},{"name":"stderr","output_type":"stream","text":["VALIDATIION: 100%|██████████| 5/5 [00:01<00:00,  3.29it/s, TRAIN=Batch_Loss 0.62 - Valid_Loss 0.51]\n"]},{"name":"stdout","output_type":"stream","text":["***** Current best checkpoint is saved. *****\n","Best valid loss: 0.5126753211021423\n","Valid loss: 0.5126753211021423 || One epoch training time: 0:00:01.526149 secs\n","#################### Epoch: 7 ####################\n"]},{"name":"stderr","output_type":"stream","text":["TRAINING: 100%|██████████| 521/521 [11:21<00:00,  1.31s/it, TRAIN=Epoch 7 - Batch_Loss 0.43 - Train_Loss 0.46 - Best_Valid_Loss 0.51]\n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 0.46414174273924724 || Time: 0:11:21.320892 secs\n"]},{"name":"stderr","output_type":"stream","text":["VALIDATIION: 100%|██████████| 5/5 [00:01<00:00,  3.28it/s, TRAIN=Batch_Loss 0.58 - Valid_Loss 0.48]\n"]},{"name":"stdout","output_type":"stream","text":["***** Current best checkpoint is saved. *****\n","Best valid loss: 0.48116494417190553\n","Valid loss: 0.48116494417190553 || One epoch training time: 0:00:01.531420 secs\n","#################### Epoch: 8 ####################\n"]},{"name":"stderr","output_type":"stream","text":["TRAINING: 100%|██████████| 521/521 [11:21<00:00,  1.31s/it, TRAIN=Epoch 8 - Batch_Loss 0.39 - Train_Loss 0.43 - Best_Valid_Loss 0.48]\n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 0.4304584808747736 || Time: 0:11:21.487014 secs\n"]},{"name":"stderr","output_type":"stream","text":["VALIDATIION: 100%|██████████| 5/5 [00:01<00:00,  3.28it/s, TRAIN=Batch_Loss 0.55 - Valid_Loss 0.46]\n"]},{"name":"stdout","output_type":"stream","text":["***** Current best checkpoint is saved. *****\n","Best valid loss: 0.458998030424118\n","Valid loss: 0.458998030424118 || One epoch training time: 0:00:01.527658 secs\n","#################### Epoch: 9 ####################\n"]},{"name":"stderr","output_type":"stream","text":["TRAINING: 100%|██████████| 521/521 [11:21<00:00,  1.31s/it, TRAIN=Epoch 9 - Batch_Loss 0.39 - Train_Loss 0.40 - Best_Valid_Loss 0.46]\n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 0.40235334880750145 || Time: 0:11:21.380513 secs\n"]},{"name":"stderr","output_type":"stream","text":["VALIDATIION: 100%|██████████| 5/5 [00:01<00:00,  3.29it/s, TRAIN=Batch_Loss 0.53 - Valid_Loss 0.44]\n"]},{"name":"stdout","output_type":"stream","text":["***** Current best checkpoint is saved. *****\n","Best valid loss: 0.4388681173324585\n","Valid loss: 0.4388681173324585 || One epoch training time: 0:00:01.528625 secs\n","#################### Epoch: 10 ####################\n"]},{"name":"stderr","output_type":"stream","text":["TRAINING: 100%|██████████| 521/521 [11:21<00:00,  1.31s/it, TRAIN=Epoch 10 - Batch_Loss 0.39 - Train_Loss 0.38 - Best_Valid_Loss 0.44]\n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 0.3792072044338695 || Time: 0:11:21.388563 secs\n"]},{"name":"stderr","output_type":"stream","text":["VALIDATIION: 100%|██████████| 5/5 [00:01<00:00,  3.29it/s, TRAIN=Batch_Loss 0.52 - Valid_Loss 0.43]\n"]},{"name":"stdout","output_type":"stream","text":["***** Current best checkpoint is saved. *****\n","Best valid loss: 0.42624243497848513\n","Valid loss: 0.42624243497848513 || One epoch training time: 0:00:01.527259 secs\n","#################### Epoch: 11 ####################\n"]},{"name":"stderr","output_type":"stream","text":["TRAINING: 100%|██████████| 521/521 [11:21<00:00,  1.31s/it, TRAIN=Epoch 11 - Batch_Loss 0.33 - Train_Loss 0.36 - Best_Valid_Loss 0.43]\n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 0.35953472277253234 || Time: 0:11:21.482229 secs\n"]},{"name":"stderr","output_type":"stream","text":["VALIDATIION: 100%|██████████| 5/5 [00:01<00:00,  3.28it/s, TRAIN=Batch_Loss 0.51 - Valid_Loss 0.41]\n"]},{"name":"stdout","output_type":"stream","text":["***** Current best checkpoint is saved. *****\n","Best valid loss: 0.4148512721061707\n","Valid loss: 0.4148512721061707 || One epoch training time: 0:00:01.527846 secs\n","#################### Epoch: 12 ####################\n"]},{"name":"stderr","output_type":"stream","text":["TRAINING: 100%|██████████| 521/521 [11:21<00:00,  1.31s/it, TRAIN=Epoch 12 - Batch_Loss 0.31 - Train_Loss 0.34 - Best_Valid_Loss 0.41]\n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 0.3424301857911694 || Time: 0:11:21.190943 secs\n"]},{"name":"stderr","output_type":"stream","text":["VALIDATIION: 100%|██████████| 5/5 [00:01<00:00,  3.29it/s, TRAIN=Batch_Loss 0.50 - Valid_Loss 0.41]\n"]},{"name":"stdout","output_type":"stream","text":["***** Current best checkpoint is saved. *****\n","Best valid loss: 0.4093626976013184\n","Valid loss: 0.4093626976013184 || One epoch training time: 0:00:01.528216 secs\n","#################### Epoch: 13 ####################\n"]},{"name":"stderr","output_type":"stream","text":["TRAINING: 100%|██████████| 521/521 [11:21<00:00,  1.31s/it, TRAIN=Epoch 13 - Batch_Loss 0.32 - Train_Loss 0.33 - Best_Valid_Loss 0.41]\n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 0.3271154597716231 || Time: 0:11:21.411466 secs\n"]},{"name":"stderr","output_type":"stream","text":["VALIDATIION: 100%|██████████| 5/5 [00:01<00:00,  3.29it/s, TRAIN=Batch_Loss 0.49 - Valid_Loss 0.40]\n"]},{"name":"stdout","output_type":"stream","text":["***** Current best checkpoint is saved. *****\n","Best valid loss: 0.4027207553386688\n","Valid loss: 0.4027207553386688 || One epoch training time: 0:00:01.525542 secs\n","#################### Epoch: 14 ####################\n"]},{"name":"stderr","output_type":"stream","text":["TRAINING: 100%|██████████| 521/521 [11:21<00:00,  1.31s/it, TRAIN=Epoch 14 - Batch_Loss 0.31 - Train_Loss 0.31 - Best_Valid_Loss 0.40]\n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 0.313554587210895 || Time: 0:11:21.487752 secs\n"]},{"name":"stderr","output_type":"stream","text":["VALIDATIION: 100%|██████████| 5/5 [00:01<00:00,  3.28it/s, TRAIN=Batch_Loss 0.49 - Valid_Loss 0.40]\n"]},{"name":"stdout","output_type":"stream","text":["***** Current best checkpoint is saved. *****\n","Best valid loss: 0.39923598170280455\n","Valid loss: 0.39923598170280455 || One epoch training time: 0:00:01.530726 secs\n","#################### Epoch: 15 ####################\n"]},{"name":"stderr","output_type":"stream","text":["TRAINING: 100%|██████████| 521/521 [11:21<00:00,  1.31s/it, TRAIN=Epoch 15 - Batch_Loss 0.27 - Train_Loss 0.30 - Best_Valid_Loss 0.40]\n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 0.3010268967005204 || Time: 0:11:21.350776 secs\n"]},{"name":"stderr","output_type":"stream","text":["VALIDATIION: 100%|██████████| 5/5 [00:01<00:00,  3.29it/s, TRAIN=Batch_Loss 0.49 - Valid_Loss 0.40]\n"]},{"name":"stdout","output_type":"stream","text":["***** Current best checkpoint is saved. *****\n","Best valid loss: 0.3966034412384033\n","Valid loss: 0.3966034412384033 || One epoch training time: 0:00:01.526514 secs\n","#################### Epoch: 16 ####################\n"]},{"name":"stderr","output_type":"stream","text":["TRAINING: 100%|██████████| 521/521 [11:21<00:00,  1.31s/it, TRAIN=Epoch 16 - Batch_Loss 0.28 - Train_Loss 0.29 - Best_Valid_Loss 0.40]\n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 0.28974874191801286 || Time: 0:11:21.426415 secs\n"]},{"name":"stderr","output_type":"stream","text":["VALIDATIION: 100%|██████████| 5/5 [00:01<00:00,  3.27it/s, TRAIN=Batch_Loss 0.48 - Valid_Loss 0.39]\n"]},{"name":"stdout","output_type":"stream","text":["***** Current best checkpoint is saved. *****\n","Best valid loss: 0.3932565271854401\n","Valid loss: 0.3932565271854401 || One epoch training time: 0:00:01.530662 secs\n","#################### Epoch: 17 ####################\n"]},{"name":"stderr","output_type":"stream","text":["TRAINING: 100%|██████████| 521/521 [11:21<00:00,  1.31s/it, TRAIN=Epoch 17 - Batch_Loss 0.29 - Train_Loss 0.28 - Best_Valid_Loss 0.39]\n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 0.27908256970303075 || Time: 0:11:21.150006 secs\n"]},{"name":"stderr","output_type":"stream","text":["VALIDATIION: 100%|██████████| 5/5 [00:01<00:00,  3.29it/s, TRAIN=Batch_Loss 0.48 - Valid_Loss 0.40]\n"]},{"name":"stdout","output_type":"stream","text":["Best valid loss: 0.3932565271854401\n","Valid loss: 0.39515977501869204 || One epoch training time: 0:00:01.526739 secs\n","#################### Epoch: 18 ####################\n"]},{"name":"stderr","output_type":"stream","text":["TRAINING: 100%|██████████| 521/521 [11:21<00:00,  1.31s/it, TRAIN=Epoch 18 - Batch_Loss 0.28 - Train_Loss 0.27 - Best_Valid_Loss 0.39]\n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 0.26866058021383415 || Time: 0:11:21.332517 secs\n"]},{"name":"stderr","output_type":"stream","text":["VALIDATIION: 100%|██████████| 5/5 [00:01<00:00,  3.29it/s, TRAIN=Batch_Loss 0.48 - Valid_Loss 0.40]\n"]},{"name":"stdout","output_type":"stream","text":["Best valid loss: 0.3932565271854401\n","Valid loss: 0.39575569033622743 || One epoch training time: 0:00:01.525969 secs\n","#################### Epoch: 19 ####################\n"]},{"name":"stderr","output_type":"stream","text":["TRAINING: 100%|██████████| 521/521 [11:23<00:00,  1.31s/it, TRAIN=Epoch 19 - Batch_Loss 0.28 - Train_Loss 0.26 - Best_Valid_Loss 0.39]\n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 0.259339102942518 || Time: 0:11:23.641188 secs\n"]},{"name":"stderr","output_type":"stream","text":["VALIDATIION: 100%|██████████| 5/5 [00:01<00:00,  3.29it/s, TRAIN=Batch_Loss 0.48 - Valid_Loss 0.39]\n"]},{"name":"stdout","output_type":"stream","text":["Best valid loss: 0.3932565271854401\n","Valid loss: 0.3942583858966827 || One epoch training time: 0:00:01.524979 secs\n","#################### Epoch: 20 ####################\n"]},{"name":"stderr","output_type":"stream","text":["TRAINING: 100%|██████████| 521/521 [11:21<00:00,  1.31s/it, TRAIN=Epoch 20 - Batch_Loss 0.23 - Train_Loss 0.25 - Best_Valid_Loss 0.39]\n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 0.2501362022191229 || Time: 0:11:21.178796 secs\n"]},{"name":"stderr","output_type":"stream","text":["VALIDATIION: 100%|██████████| 5/5 [00:01<00:00,  3.29it/s, TRAIN=Batch_Loss 0.48 - Valid_Loss 0.40]\n"]},{"name":"stdout","output_type":"stream","text":["Best valid loss: 0.3932565271854401\n","Valid loss: 0.3967757999897003 || One epoch training time: 0:00:01.525875 secs\n","#################### Epoch: 21 ####################\n"]},{"name":"stderr","output_type":"stream","text":["TRAINING: 100%|██████████| 521/521 [11:21<00:00,  1.31s/it, TRAIN=Epoch 21 - Batch_Loss 0.25 - Train_Loss 0.24 - Best_Valid_Loss 0.39]\n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 0.24133630972105344 || Time: 0:11:21.110090 secs\n"]},{"name":"stderr","output_type":"stream","text":["VALIDATIION: 100%|██████████| 5/5 [00:01<00:00,  3.28it/s, TRAIN=Batch_Loss 0.49 - Valid_Loss 0.40]\n"]},{"name":"stdout","output_type":"stream","text":["Best valid loss: 0.3932565271854401\n","Valid loss: 0.3978764474391937 || One epoch training time: 0:00:01.529402 secs\n","#################### Epoch: 22 ####################\n"]},{"name":"stderr","output_type":"stream","text":["TRAINING: 100%|██████████| 521/521 [11:21<00:00,  1.31s/it, TRAIN=Epoch 22 - Batch_Loss 0.23 - Train_Loss 0.23 - Best_Valid_Loss 0.39]\n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 0.23264889825214122 || Time: 0:11:21.439599 secs\n"]},{"name":"stderr","output_type":"stream","text":["VALIDATIION: 100%|██████████| 5/5 [00:01<00:00,  3.29it/s, TRAIN=Batch_Loss 0.49 - Valid_Loss 0.40]\n"]},{"name":"stdout","output_type":"stream","text":["Best valid loss: 0.3932565271854401\n","Valid loss: 0.4008513867855072 || One epoch training time: 0:00:01.525781 secs\n","#################### Epoch: 23 ####################\n"]},{"name":"stderr","output_type":"stream","text":["TRAINING: 100%|██████████| 521/521 [11:21<00:00,  1.31s/it, TRAIN=Epoch 23 - Batch_Loss 0.21 - Train_Loss 0.22 - Best_Valid_Loss 0.39]\n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 0.224538263341058 || Time: 0:11:21.157172 secs\n"]},{"name":"stderr","output_type":"stream","text":["VALIDATIION: 100%|██████████| 5/5 [00:01<00:00,  3.28it/s, TRAIN=Batch_Loss 0.49 - Valid_Loss 0.40]\n"]},{"name":"stdout","output_type":"stream","text":["Best valid loss: 0.3932565271854401\n","Valid loss: 0.40190368294715884 || One epoch training time: 0:00:01.528209 secs\n","#################### Epoch: 24 ####################\n"]},{"name":"stderr","output_type":"stream","text":["TRAINING: 100%|██████████| 521/521 [11:23<00:00,  1.31s/it, TRAIN=Epoch 24 - Batch_Loss 0.27 - Train_Loss 0.22 - Best_Valid_Loss 0.39]\n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 0.21682874958483134 || Time: 0:11:23.278932 secs\n"]},{"name":"stderr","output_type":"stream","text":["VALIDATIION: 100%|██████████| 5/5 [00:01<00:00,  3.29it/s, TRAIN=Batch_Loss 0.50 - Valid_Loss 0.41]\n"]},{"name":"stdout","output_type":"stream","text":["Best valid loss: 0.3932565271854401\n","Valid loss: 0.40517325401306153 || One epoch training time: 0:00:01.524020 secs\n","#################### Epoch: 25 ####################\n"]},{"name":"stderr","output_type":"stream","text":["TRAINING: 100%|██████████| 521/521 [11:31<00:00,  1.33s/it, TRAIN=Epoch 25 - Batch_Loss 0.21 - Train_Loss 0.21 - Best_Valid_Loss 0.39]\n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 0.20912583389689507 || Time: 0:11:31.423328 secs\n"]},{"name":"stderr","output_type":"stream","text":["VALIDATIION: 100%|██████████| 5/5 [00:01<00:00,  3.29it/s, TRAIN=Batch_Loss 0.50 - Valid_Loss 0.41]\n"]},{"name":"stdout","output_type":"stream","text":["Best valid loss: 0.3932565271854401\n","Valid loss: 0.40911396145820617 || One epoch training time: 0:00:01.526266 secs\n","#################### Epoch: 26 ####################\n"]},{"name":"stderr","output_type":"stream","text":["TRAINING: 100%|██████████| 521/521 [11:24<00:00,  1.31s/it, TRAIN=Epoch 26 - Batch_Loss 0.22 - Train_Loss 0.20 - Best_Valid_Loss 0.39]\n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 0.2017585842543051 || Time: 0:11:24.923630 secs\n"]},{"name":"stderr","output_type":"stream","text":["VALIDATIION: 100%|██████████| 5/5 [00:01<00:00,  3.28it/s, TRAIN=Batch_Loss 0.50 - Valid_Loss 0.41]\n"]},{"name":"stdout","output_type":"stream","text":["Best valid loss: 0.3932565271854401\n","Valid loss: 0.4115609884262085 || One epoch training time: 0:00:01.530123 secs\n","#################### Epoch: 27 ####################\n"]},{"name":"stderr","output_type":"stream","text":["TRAINING: 100%|██████████| 521/521 [11:21<00:00,  1.31s/it, TRAIN=Epoch 27 - Batch_Loss 0.21 - Train_Loss 0.19 - Best_Valid_Loss 0.39]\n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 0.19452735166746457 || Time: 0:11:21.525803 secs\n"]},{"name":"stderr","output_type":"stream","text":["VALIDATIION: 100%|██████████| 5/5 [00:01<00:00,  3.28it/s, TRAIN=Batch_Loss 0.51 - Valid_Loss 0.42]\n"]},{"name":"stdout","output_type":"stream","text":["Best valid loss: 0.3932565271854401\n","Valid loss: 0.41612209677696227 || One epoch training time: 0:00:01.527303 secs\n","#################### Epoch: 28 ####################\n"]},{"name":"stderr","output_type":"stream","text":["TRAINING: 100%|██████████| 521/521 [11:21<00:00,  1.31s/it, TRAIN=Epoch 28 - Batch_Loss 0.19 - Train_Loss 0.19 - Best_Valid_Loss 0.39]\n"]},{"name":"stdout","output_type":"stream","text":["Train loss: 0.18770109345839714 || Time: 0:11:21.642226 secs\n"]},{"name":"stderr","output_type":"stream","text":["VALIDATIION: 100%|██████████| 5/5 [00:01<00:00,  3.29it/s, TRAIN=Batch_Loss 0.51 - Valid_Loss 0.42]\n"]},{"name":"stdout","output_type":"stream","text":["Best valid loss: 0.3932565271854401\n","Valid loss: 0.4195680201053619 || One epoch training time: 0:00:01.524627 secs\n","#################### Epoch: 29 ####################\n"]},{"name":"stderr","output_type":"stream","text":["TRAINING:  42%|████▏     | 220/521 [04:48<06:35,  1.31s/it, TRAIN=Epoch 29 - Batch_Loss 0.18 - Train_Loss 0.18 - Best_Valid_Loss 0.39]\n","ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-15-42723d2cc1c2>\", line 2, in <module>\n","    trainer.train()\n","  File \"<ipython-input-10-35a2166105a9>\", line 83, in train\n","    loss.backward()\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\", line 488, in backward\n","    torch.autograd.backward(\n","  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\", line 197, in backward\n","    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n","    stb = value._render_traceback_()\n","AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 319, in wrapped\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","  File \"/usr/lib/python3.8/inspect.py\", line 1515, in getinnerframes\n","    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n","  File \"/usr/lib/python3.8/inspect.py\", line 1473, in getframeinfo\n","    filename = getsourcefile(frame) or getfile(frame)\n","  File \"/usr/lib/python3.8/inspect.py\", line 708, in getsourcefile\n","    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n","  File \"/usr/lib/python3.8/inspect.py\", line 737, in getmodule\n","    file = getabsfile(object, _filename)\n","  File \"/usr/lib/python3.8/inspect.py\", line 721, in getabsfile\n","    return os.path.normcase(os.path.abspath(_filename))\n","  File \"/usr/lib/python3.8/posixpath.py\", line 379, in abspath\n","    cwd = os.getcwd()\n","OSError: [Errno 107] Transport endpoint is not connected\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"]}],"source":["trainer = Trainer(cfg, is_train=True)\n","trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"kYCzZKoHgg8l"},"source":["##9.Evaluate"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":214},"executionInfo":{"elapsed":18547,"status":"ok","timestamp":1677694954460,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"},"user_tz":-420},"id":"YWU5ZRnOTPuG","outputId":"5e8fb28f-0efa-4deb-a335-011046711d02"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading Transformer model & Adam optimizer...\n","Loading checkpoint...\n","Tokenization already...\n","Loading sentencepiece tokenizer...\n","Setting finished.\n","Preprocessing input sentence...\n","Encoding input sentence...\n","Input: Tôi yêu bạn.\n","Result: I love you .\n","Inference finished! || Total inference time: 0:00:04.882377secs\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'I love you .'"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["cfg = NMTConfig()\n","trainer = Trainer(cfg, is_train=False, load_ckpt=True)\n","trainer.inference('Tôi yêu bạn.')"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1677694954460,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"},"user_tz":-420},"id":"Tffao98NnBGK"},"outputs":[],"source":["def evaluate(cfg, trainer):\n","    with open(cfg.data_dir + '/test.' + cfg.src_lang, 'r') as f:\n","        src_texts = f.readlines()\n","    src_texts = [s.strip() for s in src_texts]\n","\n","    with open(cfg.data_dir + '/test.' + cfg.tgt_lang, 'r') as f:\n","        tgt_texts = f.readlines()\n","    tgt_texts = [s.strip() for s in tgt_texts]\n","\n","    len(src_texts) == len(tgt_texts)\n","\n","    pred_texts = []\n","    for sent in tqdm(src_texts):\n","        pred_texts.append(trainer.inference(sent))\n","    \n","    bleu_score = sacrebleu.corpus_bleu(pred_texts, [tgt_texts], force=True)\n","\n","    return pred_texts, bleu_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qjLFYiSPn_8n"},"outputs":[],"source":["pred_texts, bleu_score = evaluate(cfg, trainer)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1677695396869,"user":{"displayName":"Thái Nguyễn Quốc","userId":"03315292090052971901"},"user_tz":-420},"id":"q_Tp22HEcCDt","outputId":"7db14d05-42b7-49e3-9479-c7f8e19cd4d9"},"outputs":[{"data":{"text/plain":["BLEU = 24.66 55.9/30.3/18.5/11.8 (BP = 1.000 ratio = 1.008 hyp_len = 28515 ref_len = 28297)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["bleu_score"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
